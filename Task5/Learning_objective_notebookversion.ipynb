{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lambeq import BobcatParser\n",
    "from discopy import grammar\n",
    "from discopy import Dim\n",
    "from lambeq import AtomicType, IQPAnsatz, remove_cups\n",
    "from pytket.extensions.qiskit import AerBackend\n",
    "from lambeq import TketModel\n",
    "from lambeq import QuantumTrainer, SPSAOptimizer\n",
    "from lambeq import Dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE =42\n",
    "EPOCHS = 100\n",
    "SEED = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input data\n",
    "def read_data(filename):\n",
    "    labels, sentences = [], []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            t = int(line[0])\n",
    "            labels.append([t, 1-t])\n",
    "            sentences.append(line[1:].strip())\n",
    "    return labels, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_data = read_data('train_data.txt')\n",
    "\n",
    "val_labels, val_data = read_data('val_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging sentences.\n",
      "Parsing tagged sentences.\n",
      "Turning parse trees to diagrams.\n",
      "Tagging sentences.\n",
      "Parsing tagged sentences.\n",
      "Turning parse trees to diagrams.\n"
     ]
    }
   ],
   "source": [
    "#Parser\n",
    "parser = BobcatParser(root_cats=('NP', 'N'), verbose='text')\n",
    "train_diagrams = parser.sentences2diagrams(train_data, suppress_exceptions=True)\n",
    "val_diagrams = parser.sentences2diagrams(val_data, suppress_exceptions=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diagrams = [\n",
    "    diagram.normal_form()\n",
    "    for diagram in train_diagrams if diagram is not None]\n",
    "val_diagrams = [\n",
    "    diagram.normal_form()\n",
    "    for diagram in val_diagrams if diagram is not None]\n",
    "\n",
    "train_labels = [\n",
    "    label for (diagram, label)\n",
    "    in zip(train_diagrams, train_labels)\n",
    "    if diagram is not None]\n",
    "val_labels = [\n",
    "    label for (diagram, label)\n",
    "    in zip(val_diagrams, val_labels)\n",
    "    if diagram is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Circuits\n",
    "ansatz = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 0},\n",
    "                   n_layers=1, n_single_qubit_params=3)\n",
    "\n",
    "train_circuits = [ansatz(remove_cups(diagram)) for diagram in train_diagrams]\n",
    "val_circuits =  [ansatz(remove_cups(diagram))  for diagram in val_diagrams]\n",
    "\n",
    "#train_circuits[0].draw(figsize=(9, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "all_circuits = train_circuits + val_circuits\n",
    "\n",
    "backend = AerBackend()\n",
    "backend_config = {\n",
    "    'backend': backend,\n",
    "    'compilation': backend.default_compilation_pass(2),\n",
    "    'shots': 8192\n",
    "}\n",
    "\n",
    "model = TketModel.from_diagrams(all_circuits, backend_config=backend_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss & eval metrics\n",
    "loss = lambda y_hat, y: -np.sum(y * np.log(y_hat)) / len(y)  # binary cross-entropy loss\n",
    "acc = lambda y_hat, y: np.sum(np.round(y_hat) == y) / len(y) / 2  # half due to double-counting\n",
    "eval_metrics = {\"acc\": acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer\n",
    "trainer = QuantumTrainer(\n",
    "    model,\n",
    "    loss_function=loss,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'a': 0.05, 'c': 0.06, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions=eval_metrics,\n",
    "    evaluate_on_train=True,\n",
    "    verbose = 'text',\n",
    "    seed=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset\n",
    "train_dataset = Dataset(\n",
    "            train_circuits,\n",
    "            train_labels,\n",
    "            batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataset = Dataset(val_circuits, val_labels, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:    train/loss: 6.4781   valid/loss: 2.9983   train/acc: 0.3750   valid/acc: 0.5625\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "trainer.fit(train_dataset, val_dataset, evaluation_step=1, logging_step=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing train model\n",
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(10, 6))\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(trainer.train_epoch_costs[::10], color=next(colours))\n",
    "ax_bl.plot(trainer.train_results['acc'][::10], color=next(colours))\n",
    "ax_tr.plot(trainer.val_costs[::10], color=next(colours))\n",
    "ax_br.plot(trainer.val_results['acc'][::10], color=next(colours))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test accuracy\n",
    "test_acc = acc(model(val_circuits), val_labels)\n",
    "print('Validation accuracy:', test_acc.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
